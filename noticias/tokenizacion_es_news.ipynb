{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>news</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.larepublica.co/redirect/post/3201905</td>\n",
       "      <td>Durante el foro La banca articulador empresari...</td>\n",
       "      <td>Otra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.larepublica.co/redirect/post/3210288</td>\n",
       "      <td>El regulador de valores de China dijo el domin...</td>\n",
       "      <td>Regulaciones</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.larepublica.co/redirect/post/3240676</td>\n",
       "      <td>En una industria históricamente masculina como...</td>\n",
       "      <td>Alianzas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.larepublica.co/redirect/post/3342889</td>\n",
       "      <td>Con el dato de marzo el IPC interanual encaden...</td>\n",
       "      <td>Macroeconomia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.larepublica.co/redirect/post/3427208</td>\n",
       "      <td>Ayer en Cartagena se dio inicio a la versión n...</td>\n",
       "      <td>Otra</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                url  \\\n",
       "0  https://www.larepublica.co/redirect/post/3201905   \n",
       "1  https://www.larepublica.co/redirect/post/3210288   \n",
       "2  https://www.larepublica.co/redirect/post/3240676   \n",
       "3  https://www.larepublica.co/redirect/post/3342889   \n",
       "4  https://www.larepublica.co/redirect/post/3427208   \n",
       "\n",
       "                                                news           Type  \n",
       "0  Durante el foro La banca articulador empresari...           Otra  \n",
       "1  El regulador de valores de China dijo el domin...   Regulaciones  \n",
       "2  En una industria históricamente masculina como...       Alianzas  \n",
       "3  Con el dato de marzo el IPC interanual encaden...  Macroeconomia  \n",
       "4  Ayer en Cartagena se dio inicio a la versión n...           Otra  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('es_news.csv', encoding='UTF-8')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['news']\n",
    "y = df['Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "\n",
    "X_train_transformed = vectorizer.fit_transform(X_train)\n",
    "X_test_transformed = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7704918032786885\n"
     ]
    }
   ],
   "source": [
    "model = MultinomialNB()\n",
    "model.fit(X_train_transformed, y_train)\n",
    "y_pred = model.predict(X_test_transformed)\n",
    "print(metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Darío\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Darío\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer('spanish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_stem(text):\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    stems = [stemmer.stem(token) for token in tokens if token.isalpha()]\n",
    "    return ' '.join(stems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['news_stemmer'] = df['news'].apply(tokenize_and_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       durant el for la banc articul empresarial par ...\n",
       "1       el regul de valor de chin dij el doming que bu...\n",
       "2       en una industri histor masculin com lo es la a...\n",
       "3       con el dat de marz el ipc interanual encaden s...\n",
       "4       ayer en cartagen se dio inici a la version num...\n",
       "                              ...                        \n",
       "1212    en la vid de tod empres emergent lleg un momen...\n",
       "1213    la espiral alcist de los preci continu y gener...\n",
       "1214    las grand derrot nacional son experient trauma...\n",
       "1215    bbva ha alcanz un acuerd de colabor con barcel...\n",
       "1216    casi entrand a la part final de noviembr la ep...\n",
       "Name: news_stemmer, Length: 1217, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['news_stemmer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_stem = df['news_stemmer']\n",
    "X_train_stem, X_test_stem, y_train, y_test = train_test_split(X_stem, y, test_size=0.2, random_state=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_stem_transformed = vectorizer.fit_transform(X_train_stem)\n",
    "X_test_stem_transformed = vectorizer.transform(X_test_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7704918032786885\n",
      "(973, 11924)\n"
     ]
    }
   ],
   "source": [
    "model_stem = MultinomialNB()\n",
    "model_stem.fit(X_train_stem_transformed, y_train)\n",
    "y_pred_stem = model_stem.predict(X_test_stem_transformed)\n",
    "print(metrics.accuracy_score(y_test, y_pred_stem))\n",
    "print(X_train_stem_transformed.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('es_core_news_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_text(text):\n",
    "    doc = nlp(text.lower())\n",
    "    lemmas = [token.lemma_ for token in doc if token.is_alpha]\n",
    "    return ' '.join(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['news_lemma'] = df['news'].apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       durante el foro el banca articulador empresari...\n",
       "1       el regulador de valor de china decir el doming...\n",
       "2       en uno industria históricamente masculino como...\n",
       "3       con el dato de marzo el ipc interanual encaden...\n",
       "4       ayer en cartagena él dar inicio a el versión n...\n",
       "                              ...                        \n",
       "1212    en el vida de todo empresa emergente llegar un...\n",
       "1213    el espiral alcista de el precio continuar y ge...\n",
       "1214    el grande derrota nacional ser experiencia tra...\n",
       "1215    bbva haber alcanzar uno acuerdo de colaboració...\n",
       "1216    casi entrar a el parte final de noviembre el é...\n",
       "Name: news_lemma, Length: 1217, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['news_lemma']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7663934426229508\n",
      "(973, 16574)\n"
     ]
    }
   ],
   "source": [
    "X_lemma = df['news_lemma']\n",
    "X_train_lemma, X_test_lemma, y_train, y_test = train_test_split(X_lemma, y, test_size=0.2, random_state=16)\n",
    "\n",
    "X_train_lemma_transformed = vectorizer.fit_transform(X_train_lemma)\n",
    "X_test_lemma_transformed = vectorizer.transform(X_test_lemma)\n",
    "\n",
    "model_lemma = MultinomialNB()\n",
    "model_lemma.fit(X_train_lemma_transformed, y_train)\n",
    "y_pred_lemma = model_lemma.predict(X_test_lemma_transformed)\n",
    "print(metrics.accuracy_score(y_test, y_pred_lemma))\n",
    "print(X_train_lemma_transformed.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopwords_removal(text):\n",
    "    doc = text.lower().split(' ')\n",
    "    es_words = stopwords.words('spanish')\n",
    "    words = [ token for token in doc if token not in es_words]\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['news_clean'] = df['news'].apply(stopwords_removal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['news_lemma_clean'] = df['news_clean'].apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7827868852459017\n",
      "(973, 17935)\n"
     ]
    }
   ],
   "source": [
    "X_lemma_clean = df['news_lemma_clean']\n",
    "X_train_lemma_clean, X_test_lemma_clean, y_train, y_test = train_test_split(X_lemma_clean, y, test_size=0.2, random_state=16)\n",
    "\n",
    "X_train_lemma_clean_transformed = vectorizer.fit_transform(X_train_lemma_clean)\n",
    "X_test_lemma_clean_transformed = vectorizer.transform(X_test_lemma_clean)\n",
    "\n",
    "model_lemma_clean = MultinomialNB()\n",
    "model_lemma_clean.fit(X_train_lemma_clean_transformed, y_train)\n",
    "\n",
    "y_pred_lemma_clean = model_lemma_clean.predict(X_test_lemma_clean_transformed)\n",
    "print(metrics.accuracy_score(y_test, y_pred_lemma_clean))\n",
    "print(X_train_lemma_clean_transformed.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['news_stemmer_clean'] = df['news_clean'].apply(tokenize_and_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7991803278688525\n",
      "(973, 11900)\n"
     ]
    }
   ],
   "source": [
    "X_stem_clean = df['news_stemmer_clean']\n",
    "X_train_stem_clean, X_test_stem_clean, y_train, y_test = train_test_split(X_stem_clean, y, test_size=0.2, random_state=16)\n",
    "\n",
    "X_train_stem_clean_transformed = vectorizer.fit_transform(X_train_stem_clean)\n",
    "X_test_stem_clean_transformed = vectorizer.transform(X_test_stem_clean)\n",
    "\n",
    "model_stem_clean = MultinomialNB()\n",
    "model_stem_clean.fit(X_train_stem_clean_transformed, y_train)\n",
    "\n",
    "y_pred_stem_clean = model_stem_clean.predict(X_test_stem_clean_transformed)\n",
    "print(metrics.accuracy_score(y_test, y_pred_stem_clean))\n",
    "print(X_train_stem_clean_transformed.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
